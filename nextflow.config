#!/usr/bin/env nextflow

/*
#
#
#  ██████╗ ██╗  ██╗██╗   ██╗██╗      ██████╗ ██████╗ ██╗  ██╗███████╗██████╗ ███████╗
#  ██╔══██╗██║  ██║╚██╗ ██╔╝██║     ██╔═══██╗██╔══██╗██║  ██║██╔════╝██╔══██╗██╔════╝
#  ██████╔╝███████║ ╚████╔╝ ██║     ██║   ██║██████╔╝███████║█████╗  ██████╔╝█████╗
#  ██╔═══╝ ██╔══██║  ╚██╔╝  ██║     ██║   ██║██╔═══╝ ██╔══██║██╔══╝  ██╔══██╗██╔══╝
#  ██║     ██║  ██║   ██║   ███████╗╚██████╔╝██║     ██║  ██║███████╗██║  ██║███████╗
#  ╚═╝     ╚═╝  ╚═╝   ╚═╝   ╚══════╝ ╚═════╝ ╚═╝     ╚═╝  ╚═╝╚══════╝╚═╝  ╚═╝╚══════╝
#
#
# PHYLOPHERE: A Nextflow pipeline including a complete set
# of phylogenetic comparative tools and analyses for Phenome-Genome studies
#
# Github: https://github.com/nozerorma/caastools/nf-phylophere
#
# Author:         Miguel Ramon (miguel.ramon@upf.edu)
#
# File: nextflow.config
#
*/

/*
 * ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 * Configuration file for setting up global parameters, process-specific resource requirements,
 * and execution profiles. This ensures optimal resource allocation and flexibility across
 * different compute environments.
 * ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 */

process.container           = 'miralnso/caastools-micromamba:latest'

// Redirect logs to stable log dir: $ export NXF_LOG_FILE="log/nextflow.log" (must be set in console before running the script)

// Global default params, used in configs
params {
    // Use singularity flipper. DO NOT MODIFY, it initializes the parameter.
    use_singularity             = use_singularity           ?: false

    // CT general option
    ct_tool                     = ct_tool                   ?:  "discovery" //"discovery,resample,bootstrap"

    // Common CT DISCOVERY and BOOTSTRAP options
    alignment                   = alignment                 ?:  "$baseDir/Data/protein_alignments/**/*" // carefull with directory substructure
    traitfile                   = traitfile                 ?:  "$baseDir/Data/CAAS_traitfiles/traitfile.tab"
    ali_format                  = ali_format                ?:  "phylip-relaxed"
    // clustal, emboss, fasta, fasta-m10, ig, maf, mauve, msf, nexus, phylip, phylip-sequential, phylip-relaxed, stockholm
    patterns                    = patterns                  ?:  "1,2,3" // Pattern 4 can be added adhoc as a parameter in the run command

    // Check CAASTOOLS DOCUMENTATION for description of these parameters
    maxbggaps                   = maxbggaps                 ?:  "NO" // From NO (no filtering) to int
    maxfggaps                   = maxfggaps                 ?:  "NO"
    maxgaps                     = maxgaps                   ?:  "NO"
    maxgapsperposition          = maxgapsperposition        ?:  "0.5"
    maxbgmiss                   = maxbgmiss                 ?:  "NO"
    maxfgmiss                   = maxfgmiss                 ?:  "0"
    maxmiss                     = maxmiss                   ?:  "NO"

    // CT RESAMPLE options
    tree                       = tree                       ?:  "$baseDir/Data/Phylogeny/tree.nwk"      // Required
    strategy                   = strategy                   ?:  "BM"                                    // Choose from random resampling or BM driven
    perm_strategy              = perm_strategy              ?:  "phylogeny"                             // If BM, choose from random perm_strategy or phylogeny driven perm_strategy
    // This is all quite confusing
    fgsize                     = fgsize                     ?:  "6"                                     // If random resampling
    bgsize                     = bgsize                     ?:  "6"                                     // If random resampling
    template                   = template                   ?:  "TBD"                                   // If random resampling
    bygroup                    = bygroup                    ?:  "TBD"                                   // If random resampling
    // Up to here Confusing
    traitvalues                = traitvalues                ?:  "TBD"                                   // If BM
    cycles                     = cycles                     ?:  "500"                                   // Number of bootstrap cycles

    // BOOTSTRAP options
    resample_out               = resample_out               ?:  null                                    // If resample has been run, specify here resample files location

    // RERCONVERGE options
    // General options
    rer_tool                   = rer_tool                   ?:  "build_trait, build_tree, build_matrix, binary, continuous" // No binary AON
    gene_trees                 = gene_trees                 ?:  "$baseDir/Data/Gene_trees/geneTrees.txt"
    my_traits                  = my_traits                  ?:  "$baseDir/Data/Cancer_data/traits.csv"      // Must be a csv file with the specified columns present
    traitname                  = traitname                  ?:  "trait"                      // How your traitcolumn is named in your dataset
    sp_colname                 = sp_colname                 ?:  "species"                                     // How your species column is named in your dataset
    trait_out                  = trait_out                  ?:  "$baseDir/Data/RER/RER_Traits/${params.traitname}.polished.output"
    trees_out                  = trees_out                  ?:  "$baseDir/Data/RER/RER_Objects/geneTrees.masterTree.pruned.output"
    matrix_out                 = matrix_out                 ?:  "${params.outdir}/RER_Objects/${params.traitname}.RERmatrix.output"

    // Continuous analysis options. Check RERConverge documentation
    rer_minsp                  = rer_minsp                  ?: "10"
    winsorizeRER               = winsorizeRER               ?: "3"
    winsorizeTrait             = winsorizeTrait             ?: "3"

    // ORA (not working AON)
    // ora                        = ora                        ?: "GO-CC,GO-BP,GO-MF,KEGG,DO,DGN,REACTOME,WP,NCG"
    // ora_plots                  = false
    // You can choose between GO-CC, GO-BP, GO-MF, KEGG, DO, DGN, REACTOME, WP, NCG

    // Boilerplate options
    outdir                     = outdir                     ?: "$baseDir/Out/Phylophere"
    monochrome_logs            = false
    hok_url                    = null
    help                       = false
    version                    = false
}

// Load base.config by default for all pipelines
// includeConfig 'conf/base.config'

// Specify that apptainer/singularity should be used and where the cache dir will be for the images.
// The singularity directive is used in favour of the apptainer one, because currently the apptainer
// variant will pull in (and convert) docker images, instead of using pre-built singularity ones.
// See https://nf-co.re/docs/usage/installation#pipeline-software
// and https://nf-co.re/tools#how-the-singularity-image-downloads-work
// See https://www.nextflow.io/docs/latest/config.html#scope-singularity
profiles {
    singularity {
        params {
            use_singularity         =  true
        }
        singularity.enabled         = true
        singularity.autoMounts      = true
        singularity.cacheDir        = "$projectDir/singularity"
        docker.enabled              = false
        podman.enabled              = false
    }
}

// Export these variables to prevent local Python/R libraries from conflicting with those in the container

env {
    PYTHONNOUSERSITE = 1
    R_PROFILE_USER   = "/.Rprofile"
    R_ENVIRON_USER   = "/.Renviron"
}

// Timestamp
def trace_timestamp = new Date().format('yyyyMMdd_HH')

// Capture exit codes from upstream processes when piping
process.shell = ['/bin/bash', '-euo', 'pipefail']

timeline {
    enabled = true
    file    = "${params.outdir}/pipeline_info/execution_timeline_${trace_timestamp}.html"
}
report {
    enabled = true
    file    = "${params.outdir}/pipeline_info/execution_report_${trace_timestamp}.html"
}
trace {
    enabled = true
    trace.overwrite = true
    file    = "${params.outdir}/pipeline_info/execution_trace_${trace_timestamp}.txt"
}
dag {
    enabled = true
    file    = "${params.outdir}/pipeline_info/pipeline_dag_${trace_timestamp}.html"
}
tower {
  accessToken = "TBA"
  enabled = true
}

manifest {
    name            = 'nf-caastools'
    author          = """Miguel Ramon Alonso"""
    homePage        = 'https://github.com/nozerorma/caastools'
    description     = """Nexflow pipeline for running CAAStools analyses"""
    mainScript      = 'main.nf'
    nextflowVersion = '!>=21.04.0'
    version         = '1.0'
    doi             = ''
}

// Function to ensure that resource requirements don't go beyond
// a maximum limit
def check_max(obj, type) {
    if (type == 'memory') {
        try {
            if (obj.compareTo(params.max_memory as nextflow.util.MemoryUnit) == 1)
                return params.max_memory as nextflow.util.MemoryUnit
            else
                return obj
        } catch (all) {
            println "   ### ERROR ###   Max memory '${params.max_memory}' is not valid! Using default value: $obj"
            return obj
        }
    } else if (type == 'time') {
        try {
            if (obj.compareTo(params.max_time as nextflow.util.Duration) == 1)
                return params.max_time as nextflow.util.Duration
            else
                return obj
        } catch (all) {
            println "   ### ERROR ###   Max time '${params.max_time}' is not valid! Using default value: $obj"
            return obj
        }
    } else if (type == 'cpus') {
        try {
            return Math.min( obj, params.max_cpus as int )
        } catch (all) {
            println "   ### ERROR ###   Max cpus '${params.max_cpus}' is not valid! Using default value: $obj"
            return obj
        }
    }
}

// Load modules.config for DSL2 module specific options
includeConfig 'conf/modules.config'

// Perform work directory cleanup when the run has succesfully completed.
// cleanup = true


// Reduce the job submit rate to about 30 per minute, this way the server
// won't be bombarded with jobs.
// Limit queueSize to keep job rate under control and avoid timeouts.
// Set read timeout to the maximum wall time.
// See: https://www.nextflow.io/docs/latest/config.html#scope-executor
executor {
    submitRateLimit = '50/1min'
    queueSize = 50
    exitReadTimeout = 7.day
}

// Define profiles for the following partitions:
// - zen2, zen3, zen3_512 (Vaughan)
// - broadwell, broadwell_256 (Leibniz)
// - skylake (Breniac, formerly Hopper)
// For each partition, there is a "*_slurm" profile and a "*_local" profile.
// The former uses the slurm executor to submit each nextflow task as a separate job,
// whereas the latter runs all tasks on the individual node on which the nextflow
// master process was launched.
// See: https://www.nextflow.io/docs/latest/config.html#config-profiles
profiles {
    // Automatic slurm partition selection based on task requirements
    slurm {
        params {
            config_profile_description = 'Config file for Marvin Cluster (UPF-CSIC), based on nf-core/configs and Pablo Carrion defaults for Nextflow run on Marvin'
            config_profile_contact = 'miguel.ramon@upf.edu (GitHub: @nozerorma)'
            config_profile_url = 'https://www.ibe.upf-csic.es'
            max_memory = 128.GB // = max memory of high memory nodes
            max_cpus = 128   // = cpu count of largest nodes
            max_time = 960.h    // wall time of longest running nodes
        }
        process {
            executor = 'slurm'
            queue = {
                // If Singularity
                if ( params.use_singularity ) {
                    'haswell'
                // If local
                } else {
                    'normal'
                }
            }
        }
    }
    // Haswell partitions
    haswell_slurm {
        process {
            executor = 'slurm'
            queue = 'haswell'
        }
    }
    haswell {
        params {
            config_profile_description = 'Config file for Marvin Cluster (UPF-CSIC), based on nf-core/configs.'
            config_profile_contact = 'miguel.ramon@upf.edu (GitHub: @nozerorma)'
            config_profile_url = 'https://www.ibe.upf-csic.es'
            max_memory = get_allocated_mem(112) // 128GB (total) - 16 GB (buffer)
            max_cpus = get_allocated_cpus(128)
            max_time = 3.day
        }
        process {
            executor = 'local'
        }
    }
        // Haswell partitions
    normal_slurm {
        process {
            executor = 'slurm'
            queue = 'normal'
        }
    }
    normal {
        params {
            config_profile_description = 'Config file for Marvin Cluster (UPF-CSIC), based on nf-core/configs.'
            config_profile_contact = 'miguel.ramon@upf.edu (GitHub: @nozerorma)'
            config_profile_url = 'https://www.ibe.upf-csic.es'
            max_memory = get_allocated_mem(112) // 128GB (total) - 16 GB (buffer)
            max_cpus = get_allocated_cpus(128)
            max_time = 3.day
        }
        process {
            executor = 'local'
        }
    }
}

// Define functions to fetch the available CPUs and memory of the current execution node.
// Only used when running one of the *_local partition profiles and allows the cpu
// and memory thresholds to be set dynamic based on the available hardware as reported
// by Slurm. Can be supplied with a default return value, which should be set to the
// recommended thresholds for the particular partition's node types.
def get_allocated_cpus(int node_max_cpu) {
    max_cpus = System.getenv("SLURM_CPUS_PER_TASK") ?: System.getenv("SLURM_JOB_CPUS_PER_NODE") ?: node_max_cpu
    return max_cpus.toInteger()
}
def get_allocated_mem(int node_max_mem) {
    def mem_per_cpu = System.getenv("SLURM_MEM_PER_CPU")
    def cpus_per_task = System.getenv("SLURM_CPUS_PER_TASK") ?: System.getenv("SLURM_JOB_CPUS_PER_NODE")

    if ( mem_per_cpu && cpus_per_task ) {
        node_max_mem = mem_per_cpu.toInteger() / 1000 * cpus_per_task.toInteger()
    }

    return "${node_max_mem}.GB"
}
